\documentclass[a4paper, 10pt]{article} %размер бумаги устанавливаем А4, шрифт 15пунктов
\usepackage[utf8]{inputenc}%кодировка
\usepackage[russian]{babel}%используем русский и английский языки с переносами
% \graphicspath{{/}}%путь к рисункам
\usepackage{cite}
\usepackage{multirow}
\usepackage{float}
\usepackage{tikz}
\usetikzlibrary{arrows}
\usepackage{ amssymb }
\usepackage{ amsmath}
\usepackage{listings}
\usepackage{xcolor}
\definecolor{dkgreen}{rgb}{0,0.6,0}
\definecolor{dred}{rgb}{0.545,0,0}
\definecolor{dblue}{rgb}{0,0,0.545}
\definecolor{lgrey}{rgb}{0.9,0.9,0.9}
\definecolor{gray}{rgb}{0.4,0.4,0.4}
\definecolor{darkblue}{rgb}{0.0,0.0,0.6}
\lstdefinelanguage{cpp}{
    backgroundcolor=\color{lgrey},  
    basicstyle=\footnotesize \ttfamily \color{black} \bfseries,   
    breakatwhitespace=false,       
    breaklines=true,               
    captionpos=b,
    commentstyle=\color{dkgreen},   
    deletekeywords={...},          
    escapeinside={\%*}{*)},                  
    frame=single,                  
    language=C++,                
    keywordstyle=\color{purple},  
    morekeywords={size_t,string,void,int,gc_ptr,gc_new}, 
    identifierstyle=\color{black},
    stringstyle=\color{blue},
    numbers=right,                 
    numbersep=5pt,                  
    numberstyle=\tiny\color{black}, 
    rulecolor=\color{black},        
    showspaces=false,               
    showstringspaces=false,        
    showtabs=false,                
    stepnumber=1,                   
    tabsize=5,                     
    title=\lstname,                 
}

\usepackage{fontspec}
\usepackage{polyglossia}
\setdefaultlanguage{russian}
\setmainfont[Ligatures=TeX]{DejaVu Serif}
\setsansfont[Ligatures=TeX]{DejaVu Sans}
\setmonofont{DejaVu Sans Mono}

\usepackage{geometry} % Меняем поля страницы
\geometry{left=3.5cm}% левое поле
\geometry{right=2.5cm}% правое поле
\geometry{top=4cm}% верхнее поле
\geometry{bottom=4cm}% нижнее поле

\newcommand{\bi}{\begin{itemize}}
\newcommand{\ei}{\end{itemize}}
\newcommand{\be}{\begin{enumerate}}
\newcommand{\ee}{\end{enumerate}}
\newcommand{\ii}{\item}

\newcommand{\red}[1]{{\color{red}#1}}
\newcommand{\green}[1]{{\color{blue!20!black!30!green}#1}}
\newcommand{\blue}[1]{{\color{blue}#1}}
\newcommand{\brown}[1]{{\color{brown}#1}}
\newcommand{\browm}[1]{{\color{browm}#1}}
\newcommand{\violet}[1]{{\color{violet}#1}}

\newcommand{\lam}[1]{{\color{brown}\emph{\boldmath{#1}}}}
\newcommand{\lexp}{$\lambda$-expression}
\newcommand{\lc}{$\lambda$-calculus}
\newcommand{\ba}{\begin{array}}
\newcommand{\ea}{\end{array}}

\newcommand{\lsem}{\mbox{$\lbrack\hspace{-0.3ex}\lbrack$}}
\newcommand{\rsem}{\mbox{$\rbrack\hspace{-0.3ex}\rbrack$}}

\newcommand{\bc}{\begin{center}}
\newcommand{\ec}{\end{center}}

\begin{document}

Good afternoon, my name is Daniil and I'm going to present our joint work with 
professor Neil Deaton Jones, called ``Partial Evaluation and Normalization by 
Traversals''. 


====================================================\\
=== slide ??: introduction =========================\\
====================================================


\#TODO:
Reformulate: game semantics for various versions of lambdas.

\#The game semantics for PCF can be thought of as a PCF interpreter.
\#In a set of game semantics papers the denotation of an expression
\#is a game strategy. When played, the game results in a traversal.

For example, Luke Ong’s recent paper ``Normalization by Traversals''
shows that a \blue{\emph{simply-typed lambda-expression \lam{M}}}
can be \red{evaluated} (i.e. normalised) by the algorithm that
constructs a \green{traversal} of \lam{M}.

A \green{\emph{traversal}} in this case is a justified sequence
of subexpressions of \lam{M}. For brivety, we will call them
\green{\emph{tokens}}.  One can think, that M is 
a \blue{program} and token is a \blue{program point}. Any token
may have a \green{\emph{back pointer}}, or justifier, to some other 
previously encountered token. These pointers are used to lookup some 
information about \lexp in the history of computation and to find
dynamic binders for variables.

Hereafter we will call this approach to normalization of simply typed
lambda terms Oxford Normalization Procedure, or ONP. For a given \lexp
\lam{$M$} \lam{ONP} constructs a set of traversals
\lam{$\mathfrak{Trav}(M)$}, each of which corresponds to some
\underline{path} in normalized term tree.


====================================================\\
=== slide ??: starting point =======================\\
====================================================

\# Confirm the understanding of operational view and its motivation.
In the context of our research, we are interested in \emph{operational}, 
algorithmic view of game semantics-based normalization without direct
reference to game semantic foundations (?).

Consider a traversal \lam{$tr$} from \lam{$\mathfrak{Trav}(M)$}, which is
a sequence of tokens \lam{$t_0$} \lam{$t_n$}.

For all such traversals from \lam{$\mathfrak{Trav}(M)$} \lam{ONP} adds on
each step zero or more extensions to \lam{$\mathfrak{Trav}(M)$}. 
If none is added, then the traversal $tr$ already represents some path in
the tree of $\beta$-normal $\eta$-long form of the term.

Each extension is a traversal, obtained by concatenation of traversal
\lam{$tr$} and \underline{one new token} \lam{$t'$}, which may be
equipped with a pointer to some previous token in \lam{$tr$}.

Moreover, \lam{ONP} uses inference rules, discriminated solely by sintax
of end-tokens \lam{$t_n$}. In other words, \lam{ONP} is \blue{syntax-directed}.

In terms of implementation, we have two main \underline{data types}:
traversals and items. \underline{Traversal} is just a list of
\underline{items}, where an item is a pair: a token and its (optional) 
backpointer.

====================================================\\
=== slide ??: SOME ONP CHARACTERISTICS =============\\
====================================================

Now then, let's summarize some importants for us properties of \green{ONP}.

Fisrt, \lam{ONP} can be applied only to \blue{simply-tiped} $\lambda$-terms
in \blue{$\eta$-long form}. The $\eta$-long form is obtained by $\eta$-
expanding term fully and replacing implicit binary application operator of
each redex by the \emph{long application operator} $@$. The crucial
point is that in order to perform this expansion one needs to know the exact 
types of all subterms.

Second, \lam{ONP} implements \green{\underline{complete} head linear
reduction}. Complete head linear reduction can be seen as regular
\emph{head linear reduction} followed by regular \emph{head linear 
reductions} of all arguments.

The correctness of normalization by traversals is proven in terms of game 
semantics and categories, and fully based on \lam{$M$}'s types.

Then, in contrast to standart evaluation approaches, normalization by 
traversals uses \red{\underline{no $\beta$-reductions}}, leaves the original 
term intact, and can be implemented without resorting to \emph{traditional 
techniques} like environments, closures etc.

Finally, an important property of \lam{ONP} is that while running, \lam{ONP}
does not use type information at all. As it was mentioned before, \lam{ONP} 
constructs traversals using only \blue{syntax-derected rules}.

And now we are able to formulate the \textbf{goals} of our research:
\bi
\ii The first goal is to extend \green{ONP} to the untyped case (hereafter
\green{UNP});
\ii The second is to reexamine the outcomes of partial evaluation in the
light of alternative evaluation technique.
\ei


====================================================\\
=== slide ??: PARTIAL EVALUATION, BRIEFLY =========\\
======================================================

Now let breafly remined what is partial evaluation and disscuss
an effect of its application to normalizer.

Partial evaluation is a program optimization technique also known
as \blue{program specialization}.
A one-argument function can be obtained from one with two arguments by
specialization, i.e. by ``freezing'' one input to a fixed value.
A partial evaluator by given subject program together with part of its input
data $s$ constructs a new program $p_{s}$ which, when given $p$'s remaining 
input $d$, will yield the same result that $p$ would have produced
given both inputs.

\bi

\ii Partial evaluation yeilds program speed up by \green{precomputing} all 
  static input at compile time.

\ii Thus, while talking about partial evaluation data $s$ is called
  \red{static}, data $d$ --- dynamic, and program $p_s$ that is build by
  specializer is called \blue{residual}.

\ii A net effect of partial evaluation is a \blue{staging program
  transformation}. Partial evaluation devides one-stage program computation
  in two stages:
  \be
  \ii optimized residual program generation and
  \ii running the generated program on some dynamic data.
  \ee

\ii Most successful applications of PE are \blue{compilation} and 
  \blue{compiler generator}.
  For example, partial evaluation of an interpreter with respect to a source 
  program yields a target program.
  Moreover, a well-known fact about partial evaluation is that
  if provided the partial evaluator is self-applicable,
  then \blue{compiler generation} is possible by specializing the partial 
  evaluator itself with respect to a fixed interpreter yields a compiler.
  Finally, specializing the partial evaluator with respect to itself yields 
  a \blue{compiler generator}.

\ii An old idea: use partial evaluation to provide \blue{Semantics-directed 
  compiler generation}.
  By this we mean more than just a tool to help humans write compilers. Given
  a specfication of a programming language, like a formal semantics or 
  an interpreter, the goal is automatically and correctly transform it into a 
  compiler.
  The motivation for automatic compiler generation is evident:
  the three jobs of writing the language specfication, writing the compiler,
  and showing the compiler to be correct are reduced to one: writing the 
  language specfication in a form suitable as input to the compiler generator.

\ei


====================================================\\
=== slide ??: why partially evaluate ONP =============\\
======================================================

The $spec$ equation for a normaliser program \textbf{NP} that is just a function from lambda-calculus to Traversals can be seen on the slide.

You can see that there is no external dynamic
data and that is a tradition for $\lambda$-calculus that $\lambda$-term \lam{M} is self-contained.

So a question is \textbf{why break normalization into two stages?}

Well, ... , there are several reasons for it:
\be
\ii First, a specialiser output $\mbox{NP}_M = \lsem spec \rsem (\mbox{NP}, M)$
  can be in a \blue{much simplier language} than $\lambda$-calculus.
  And our candidate for it is some \textbf{\brown{low-level language}} called \lam{LLL}.

\ii Second, two stages will be natural for \blue{\em semantics-directed compiler generation}.\\
  Our \green{aim is to use \lam{LLL} as an intermediate language to express \red{semantics}}.\\
  Programs on this low-level language can be thought as a \red{semantics}
  for programs from $\lambda$-calculus.\\
  In other words, we \red{factor} the initial normalization procedure $\mbox{NP}$ into two stages:\\
  First stage that called $\mbox{NP}_1$ is a result of partially evaluating 
  normalization procedure to input term \lam{$M$}\\
  $\mbox{NP}_1\;=\; \lsem spec \rsem\; \mbox{NP}\; M\;:\; \Lambda \rightarrow LLL$\\
  and the second stage, $\mbox{NP}_2$ is the \emph{semantic function} of LLL-programs\\
  $\mbox{NP}_2\;=\; \lsem \cdot \rsem\; :\; LLL \rightarrow Traversals$.
\ee
\ \\



====================================================\\
=== slide ??: how to partially evaluate ONP ==========\\
======================================================

A next question is "how to partially evaluate oxford nomalization procedure
with respect to the \red{static} input term \lam{$M$}"?

\be
\ii First, we have to \blue{annotate} parts of normalization procedure as either \green{static} or \red{dynamic}. And here variables ranging over
  \be
  \ii\label{onpsyntax} \green{tokens} that are \green{static}, \\
    Because there are only \blue{finitely many} subexpressions of \lam{$M$}.\\\\
    And all other data is actually dynamic
  \ii\label{onpbps} i.e. \red{back pointers} are \red{dynamic};
  \ii\label{onptraversals} and so the \red{traversal} being built from both of them is \red{dynamic} too.
  \ee
\ii Computations in normalization proicedure \textbf{NP} are either 
  \green{unfolded} by partial evaluator in compile time or \red{residualised}
  that means that partial evaluator will generate a runtime code to \red{do them later} in run-time.\\
  And then
  \bi
  \ii Perform all \green{fully static} computations  \green{at partial evauation time}.
  \ii and for operations to build or test a traversal: generate \red{residual code}.
  \ei
\ee
\ \\



====================================================\\
=== slide ??: The  residual program \lam{ONP}$_{\lam{$M$}} = \lsem \lowercase{spec}\rsem \, \mbox{NP}\ \lam{$M$}$ ===============\\
======================================================

Now we will talk about structure of a spesialized program \lam{ONP}$_{\lam{$M$}}$.

Note, that \lam{ONP} is not quite structually inductive but it is \red{semi-compositional}:\\ in a sence that
\hfill\green{Any recursive \lam{ONP} call has \underline{\underline{a substructure of $M$}} as argument.}

This property has several \blue{consequences}:
\bi
\item Firts, the partial evaluator can do, at specialisation time, 
  \blue{all of the \lam{ONP} operations that depend only on input term \lam{$M$}}
\item \blue{wherein} this also means that \lam{ONP$_M$} performs \green{\underline{no operations at all}} on  lambda expressions(!)\\

and for all other operations
\item the specialised program \lam{ONP$_M$} will be generated. This program contains ``residual code'', that means that it contains only
  operations to build the traversal. There are two kind of operation to do this:
  \bi
  \item operations to extend the traversal; and sometimes
  \item operations to follow back pointers when needed to do this
  \ei
\item An important fact is that subexpressions of \lam{$M$} will appear, but are only used as \red{tokens}:\\
  This means that tokens are \green{indivisible}: they are only used as labels (i.e. program points) and for equality comparisons with other tokens.
  Actually we use names instead of real subexpressions.
  And real subexpressions is only needed for the normalized term reconstruction from traversals.
\ei
\ \\



====================================================\\
=== slide ??: Status: our work on simply-typed \lc ===\\
======================================================

Status of our work for symply-tiped \lc \ is as follows:

\be
\item We have one version of \lam{ONP} writen in \blue{\sc Haskell} and another in \blue{\sc Scheme}
\item The {\sc Haskell} version includes: \green{typing} using algorithm $W$; \green{conversion to eta-long form; the traversals generation algorithm itself; and construction of the normalised term from the set of traversals}.
\item While {\sc Scheme} version is nearly ready to apply automatic partial evaluation.
  We are planning to use  the \blue{\sc unmix} partial evaluator that is written by Sergei Romanenko and others. {\sc unmix} is a general partial evaluator for {\sc Scheme}. We expect that we will achieve
  the described above effect of specialising \lam{ONP}.
\item An important fact is that the \lam{LLL} output program size is only \red{linearly larger}
  than \lam{$M$}, satisfying
  $$|p_M| = O(|M|)$$
  while traversal itself can be unboundaly larger than size of the input term.
\item We have also have a handwritten a \red{\em generating extension} of \lam{ONP} $ONP-gen$. 
  Symbolically,
  $$
  \mbox{If\ }p_M = \lsem \mbox{ONP-gen} \rsem^{\sc scheme} (M)
  \mbox{\ then\ }
  \forall M \ .\ \lsem M\rsem^\Lambda =  \lsem p_M \rsem^{LLL} 
  $$
  It means that by given $\lambda$-term \lam{$M$} $OMP-gen$ generates an LLL program $p_{\lam{$M$}}$ that being executed generates a traversal for \lam{$M$}.

  \green{For now: \lam{LLL} is a tiny subset of {\tt scheme}, so the output $p_M$ is a {\sc scheme} program}.


\item There are more thing to do for simply-typed \lc:
  \bi
  \ii First, produce a generating extension \green{automatically} by \blue{specialising the specialiser to a $\Lambda$-traverser} using {\sc unmix}.
  \ii Second, redefine \lam{LLL} formally as a \emph{clean stand-alone tiny \underline{first-order} subset} of {\sc haskell}
    and use haskell supersompiler to achive a partial evaluation effect.
  \ii Also we whant to extend existing approach to \green{programs with input \red{dynamic} data} in run-time.
  \ei
\ee
\ \\



====================================================\\
=== Status:  our work on the \blue{untyped} \lc ======\\
======================================================

For \blue{untyped} \lc

\be
\ii We have a normaliser \lam{UNP} that is a normaliser for arbitrary untyped lambda term.
\ii \lam{UNP} has been done in {\sc Haskell} and works on a variety of examples.
  Right now we are working on a more abstract definition of \lam{UNP}.
\ii Some of traversal items may have \blue{two back pointers}, in comparison: \lam{ONP} uses only one.
\ii As \lam{ONP}, \lam{UNP} is also defined \green{semi-compositionally} by recursion on  syntax of $\lambda$-expression \lam{$M$}.
  This actually means that it also can be specialized as \lam{ONP} can.
\ii Moreover, by specialising \lam{UNP}, an \blue{arbitrary untyped $\lambda$-expression} can be translated to our low-level language.
  So the specialised version of \lam{UNP} could be a semantic function
  for \lc.
\ii Correctness proof: pending. For now, we are working on a correctness proof for UNP.
  We expect that we will prove its correctness formally using some proof assistant like \textbf{Coq}.
\ee
\ \\



====================================================\\
=== Status: Towards separating programs from data in $\Lambda$
===============================================

Also we have a one more direction for research:
\be
\ii An idea is to regard a \green{computation of $\lambda$-expression \lam{$M$} on input $d$} as a
  \red{ \blue{two-player game} between the {\sc lll}-codes for \lam{$M$} and $d$}.
\ii An intresting examples in this case a is usual $\lambda$-calculus definition of multiply function ($mult$)
  on Church numerals.
\ii Amaizing fact is that \textbf{Loops from out of nowhere}:
  \bi
  \ii \green{Neither {\tt mult} nor the data contain loops};
  \ii but  {\tt mult} function is compiled into \blue{an {\lam{LLL}}-program with two nested loops}, one to each input numeral,
    that being applied to two Church numerals computes their product.
  \ii We expect that we can do the computation \green{entirely without back pointers}.
  \ei
\ii Right now we are trying to express such program-data games in a \red{\em communicating}
  version of \lam{LLL}. 
\ee



\end{document}
